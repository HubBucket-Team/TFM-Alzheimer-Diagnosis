{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BuildingTFRecordsDB.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["k7nfNbmCtivM"]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nffWgzNAHxSN"},"source":["# BUILDING A TFRECORDS DATABASE\n","\n","In this notebook, a TFRecords database is built from the MRI dataset that has already been organized in folders, according to the possible labels:\n","\n","* CN\n","* MCI\n","* AD\n","\n","The code for that organization is in the notebook named `ImagePreprocessing.ipynb`. This notebook is the first one executed using Google Colaboratory. The objective is to create a series of `.tfrecords` files encoding the entire ADNI dataset. Since it is very big and Google Colab offers 12GB of RAM, it was mandatory to use this format to avoid the use of native Python generators, which would be way too slow for training.\n","\n","First, mount Google Drive on this notebook."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1561715921218,"user_tz":-60,"elapsed":487,"user":{"displayName":"Oscar Darias","photoUrl":"https://lh5.googleusercontent.com/-LRfbx-yLpIQ/AAAAAAAAAAI/AAAAAAAARJA/7oZPXtss-vU/s64/photo.jpg","userId":"01395086989309546998"}},"id":"71mUm_XCAeBa","outputId":"06e69c81-c40a-4056-b5b5-111eb6803ba2","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lMI0QWB1LEXc"},"source":["`SimpleITK` has to be installed, because it is not installed by default on Colab. `DLTK` will also be very useful for some preprocessing steps, like whitening. Using `pip` will do."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"k0vr9P7LF8mQ","colab":{}},"source":["! pip install SimpleITK\n","! pip install dltk"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UGXhKCz3LIsj"},"source":["Import all the needed libraries. A brief description of them:\n","\n","* `Tensorflow` is the selected deep learning framework.\n","* `SimpleITK` for reading `.nii` images.\n","* `numpy` for working with numbers and matrixes. It is also necessary for `SimpleITK` to work properly.\n","* `pandas` for loading the data description file.\n","* `keras` will be used for model construction, working on `tensorflow`.\n","* `dltk.io.preprocessing` for whitening the images\n","* `matplotlib.pyplot` for image visualization\n","* `os` for file interaction"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CRhYS3-oCWbJ","colab":{}},"source":["import tensorflow as tf\n","import SimpleITK as sitk\n","import numpy as np\n","import pandas as pd\n","\n","from tensorflow import keras\n","from dltk.io import preprocessing\n","from matplotlib import pyplot as plt\n","\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"51oRJIhQC_oT","colab_type":"text"},"source":["---\n","\n","## PREVIOUS STEPS"]},{"cell_type":"markdown","metadata":{"id":"Y_cV4De3hG9S","colab_type":"text"},"source":["Implement methods to build a `tf.train.Feature` from a basic python or numpy datatype. This is a basic step towards building any TFRecords database."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H_19mxUaCQ6C","colab":{}},"source":["def _int64_feature(value):\n","  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","def _float_feature(value):\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n","  \n","def _bytes_feature(value):\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RfElG_2RhSSp","colab_type":"text"},"source":["Define all constants that allow us to access our data:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xfM3-MVwCRt-","colab":{}},"source":["# basic RAW databases, with registrated and skull-stripped images\n","DB_REG_PATH = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/ADNI/MRI/REGISTERED/'\n","DB_SS_PATH = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/ADNI/MRI/SKULL-STRIPPED/'\n","\n","# the data description file\n","DESCRIPTION_FILE = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/ADNI/MRI/Description.csv'\n","\n","# data subfolders (labels)\n","CLASS_SUBFOLDERS = ['MCI/', 'AD/', 'CN/']\n","BINARY_CLASS_SUBFOLDERS = ['AD/', 'CN/']\n","\n","# database with the unsupervised learning data\n","DB_UL_PATH = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/UNSUPERVISED/REGISTERED/'\n","DB_UL_SS_PATH = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/UNSUPERVISED/SKULL-STRIPPED/'\n","\n","# 3D supervised TFRecords database\n","DB_TF_3D_PATH = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/TFRecords/MRI/TFRecords3D/'\n","# tfrecords files - registered and skull stripped\n","TFREC_3D_REG_TRAIN = 'train.3D.registered.tfrecords'\n","TFREC_3D_SS_TRAIN = 'train.3D.skull_stripped.tfrecords'\n","TFREC_3D_REG_TEST = 'test.3D.registered.tfrecords'\n","TFREC_3D_SS_TEST = 'test.3D.skull_stripped.tfrecords'\n","TFREC_3D_REG_VAL = 'validation.3D.registered.tfrecords'\n","TFREC_3D_SS_VAL = 'validation.3D.skull_stripped.tfrecords'\n","\n","# 2D supervised TFRecords database\n","DB_TF_2D_PATH = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/TFRecords/MRI/TFRecords2D/'\n","# tfrecords files - registered and skull stripped\n","# also created a binary tfrecord, which was intended to be used for binary classification (deprecated)\n","TFREC_2D_REG_TRAIN = 'train.2D.registered.tfrecords'\n","TFREC_2D_SS_TRAIN = 'train.2D.skull_stripped.tfrecords'\n","TFREC_2D_BIN_TRAIN = 'train.2D.binary.tfrecords'\n","TFREC_2D_REG_TEST = 'test.2D.registered.tfrecords'\n","TFREC_2D_SS_TEST = 'test.2D.skull_stripped.tfrecords'\n","TFREC_2D_BIN_TEST = 'test.2D.binary.tfrecords'\n","TFREC_2D_REG_VAL = 'validation.2D.registered.tfrecords'\n","TFREC_2D_SS_VAL = 'validation.2D.skull_stripped.tfrecords'\n","TFREC_2D_BIN_VAL = 'validation.2D.binary.tfrecords'\n","\n","\n","# 3D unsupervised TFRecords database\n","DB_TF_UL_PATH = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/TFRecords/MRI/TFRecordsUL/'\n","# tfrecords files - registered and skull stripped\n","TFREC_UL_REG_TRAIN = 'train.UL.registered.tfrecords'\n","TFREC_UL_SS_TRAIN = 'train.UL.skull_stripped.tfrecords'\n","TFREC_UL_REG_TEST = 'test.UL.registered.tfrecords'\n","TFREC_UL_SS_TEST = 'test.UL.skull_stripped.tfrecords'\n","TFREC_UL_REG_VAL = 'validation.UL.registered.tfrecords'\n","TFREC_UL_SS_VAL = 'validation.UL.skull_stripped.tfrecords'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E693ULwrh6ct","colab_type":"text"},"source":["Identifiers for the three different classes are needed. Also save the shape of the images, in case that information is needed."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JtdIF5WZM7kL","colab":{}},"source":["# label mapping\n","LABELS = {'CN': 0, 'MCI': 1, 'AD': 2}\n","BINARY_LABELS = {'CN': 0, 'AD': 1}\n","\n","# shape of the images, both 3D and 2D\n","IMG_SHAPE = (78, 110, 86)\n","IMG_2D_SHAPE = (IMG_SHAPE[1] * 4, IMG_SHAPE[2] * 4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YqmIO24rGz4X","colab_type":"text"},"source":["\n","Define the percentage of the data that are going to be used as a test and validation set. When using TFRecords, data has to be separated in different files, because they cannot be splitted later in training."]},{"cell_type":"code","metadata":{"id":"o0PYujlnGv5v","colab_type":"code","colab":{}},"source":["TEST_SPLIT = 0.15\n","VALIDATION_SPLIT = 0.15"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7hx298lHPQG","colab_type":"text"},"source":["---\n","\n","## SUPERVISED DATA"]},{"cell_type":"markdown","metadata":{"id":"OzDp2oqqfNRT","colab_type":"text"},"source":["### Train/Test supervised data split\n","\n","Find a way to split the data. Load the path of every file in a list, and then split the list so the references of training, validation and test data are separated."]},{"cell_type":"code","metadata":{"id":"2e3ouWagHZki","colab_type":"code","colab":{}},"source":["# array for saving the filenames\n","filenames = np.array([])\n","\n","# iterate all three class folders in the db\n","for subf in CLASS_SUBFOLDERS:\n","  # using the skull stripped data\n","  path = DB_SS_PATH + subf\n","  for name in os.listdir(path):\n","    complete_name = os.path.join(path, name)\n","    if os.path.isfile(complete_name):\n","      filenames = np.concatenate((filenames, complete_name), axis=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMjgqB66XSfj","colab_type":"code","outputId":"eb9b339e-7e06-4759-8f47-eced9c40c9c2","executionInfo":{"status":"ok","timestamp":1561715953714,"user_tz":-60,"elapsed":353,"user":{"displayName":"Oscar Darias","photoUrl":"https://lh5.googleusercontent.com/-LRfbx-yLpIQ/AAAAAAAAAAI/AAAAAAAARJA/7oZPXtss-vU/s64/photo.jpg","userId":"01395086989309546998"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["filenames.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1539,)"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"cxREO7gffQxy","colab_type":"text"},"source":["Now, shuffle and split the `ndarray`:"]},{"cell_type":"code","metadata":{"id":"UIO5OEfSKvHg","colab_type":"code","outputId":"2435d05a-f60a-4daf-8828-8751a98433e0","executionInfo":{"status":"ok","timestamp":1561715958468,"user_tz":-60,"elapsed":726,"user":{"displayName":"Oscar Darias","photoUrl":"https://lh5.googleusercontent.com/-LRfbx-yLpIQ/AAAAAAAAAAI/AAAAAAAARJA/7oZPXtss-vU/s64/photo.jpg","userId":"01395086989309546998"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["for i in range(1000):\n","  np.random.shuffle(filenames)\n","  \n","test_margin = int(len(filenames) * TEST_SPLIT)\n","training_set, test_set = filenames[test_margin:], filenames[:test_margin]\n","\n","validation_margin = int(len(training_set) * VALIDATION_SPLIT)\n","training_set, validation_set = training_set[validation_margin:], training_set[:validation_margin]\n","\n","print('Training set:', training_set.shape)\n","print('Validation set:', validation_set.shape)\n","print('Test set:', test_set.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training set: (1113,)\n","Validation set: (196,)\n","Test set: (230,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k7nfNbmCtivM"},"source":["\n","### 3D TFRecords database for supervised learning\n","\n","Let´s build the 3D TFRecords database for supervised learning. Keep in mind that this code can be reused to create databases for both skull-stripped and non-skull-stripped data, just by modifying the referenced constants. The final work used the skull stripped data.\n"]},{"cell_type":"markdown","metadata":{"id":"RPHKRdZ6HuIi","colab_type":"text"},"source":["Load the data description file."]},{"cell_type":"code","metadata":{"id":"9bz9oZ90kGj3","colab_type":"code","outputId":"4eee2b56-dc44-4708-88f2-3a6d5aa89d05","executionInfo":{"status":"ok","timestamp":1560011611464,"user_tz":-60,"elapsed":539,"user":{"displayName":"Oscar Darias","photoUrl":"https://lh5.googleusercontent.com/-LRfbx-yLpIQ/AAAAAAAAAAI/AAAAAAAARJA/7oZPXtss-vU/s64/photo.jpg","userId":"01395086989309546998"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["description = pd.read_csv(DESCRIPTION_FILE)\n","description.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image Data ID</th>\n","      <th>Subject</th>\n","      <th>Group</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Visit</th>\n","      <th>Modality</th>\n","      <th>Description</th>\n","      <th>Type</th>\n","      <th>Acq Date</th>\n","      <th>Format</th>\n","      <th>Downloaded</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>97327</td>\n","      <td>941_S_1311</td>\n","      <td>MCI</td>\n","      <td>M</td>\n","      <td>69</td>\n","      <td>1</td>\n","      <td>MRI</td>\n","      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n","      <td>Processed</td>\n","      <td>3/02/2007</td>\n","      <td>NiFTI</td>\n","      <td>4/04/2019</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>97341</td>\n","      <td>941_S_1311</td>\n","      <td>MCI</td>\n","      <td>M</td>\n","      <td>70</td>\n","      <td>3</td>\n","      <td>MRI</td>\n","      <td>MPR-R; GradWarp; B1 Correction; N3; Scaled</td>\n","      <td>Processed</td>\n","      <td>9/27/2007</td>\n","      <td>NiFTI</td>\n","      <td>4/02/2019</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>112538</td>\n","      <td>941_S_1311</td>\n","      <td>MCI</td>\n","      <td>M</td>\n","      <td>70</td>\n","      <td>4</td>\n","      <td>MRI</td>\n","      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n","      <td>Processed</td>\n","      <td>6/01/2008</td>\n","      <td>NiFTI</td>\n","      <td>4/02/2019</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>75150</td>\n","      <td>941_S_1202</td>\n","      <td>CN</td>\n","      <td>M</td>\n","      <td>78</td>\n","      <td>3</td>\n","      <td>MRI</td>\n","      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n","      <td>Processed</td>\n","      <td>8/24/2007</td>\n","      <td>NiFTI</td>\n","      <td>4/02/2019</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>105437</td>\n","      <td>941_S_1202</td>\n","      <td>CN</td>\n","      <td>M</td>\n","      <td>79</td>\n","      <td>4</td>\n","      <td>MRI</td>\n","      <td>MPR; GradWarp; B1 Correction; N3; Scaled</td>\n","      <td>Processed</td>\n","      <td>2/28/2008</td>\n","      <td>NiFTI</td>\n","      <td>4/02/2019</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Image Data ID     Subject Group Sex  ...       Type   Acq Date Format Downloaded\n","0          97327  941_S_1311   MCI   M  ...  Processed  3/02/2007  NiFTI  4/04/2019\n","1          97341  941_S_1311   MCI   M  ...  Processed  9/27/2007  NiFTI  4/02/2019\n","2         112538  941_S_1311   MCI   M  ...  Processed  6/01/2008  NiFTI  4/02/2019\n","3          75150  941_S_1202    CN   M  ...  Processed  8/24/2007  NiFTI  4/02/2019\n","4         105437  941_S_1202    CN   M  ...  Processed  2/28/2008  NiFTI  4/02/2019\n","\n","[5 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"markdown","metadata":{"id":"sct3YRG2Hwo4","colab_type":"text"},"source":["Now, design a method that loads a 3D `.nii` image and some of its information. Taking the absolute path, split the name by directories to get the image name. With that, obtain the class label. Also, obtain the subject ID from the image file name. Finally, read the image using `SimpleITK`, transform into a `numpy` array and return the image, the label and the subject ID."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"22fu5WqiFUlK","colab":{}},"source":["def load_image_3D(abs_path):\n","  ''' Load an image (.nii) and its label, from its absolute path.\n","      \n","      Parameters:\n","        abs_path -- Absolute path, filename included\n","        \n","      Returns:\n","        img -- The .nii image, converted into a numpy array\n","        label -- The label of the image\n","        \n","  '''\n","  \n","  # obtain the label from the path (it is the last directory name)\n","  split_path = abs_path.split('/')\n","  label = LABELS[split_path[-2]]\n","  \n","  # obtain the ID of the subject\n","  img_name = split_path[-1]\n","  subject = '_'.join(img_name.split('_')[1:4])\n","  \n","  # load the image with SimpleITK\n","  sitk_image = sitk.ReadImage(abs_path)\n","  \n","  # transform into a numpy array\n","  img = sitk.GetArrayFromImage(sitk_image)\n","  \n","  return img, label, subject"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S-Skj_YbIgIU","colab_type":"text"},"source":["Now, create a new method for creating `.tfrecords` files. It would be necessary to specifiy the filenames of all the images that are going to be stored in the `.tfrecords`, as well as the name for this file. Then, follow the common strategy for creating this type of files, like it can be seen in countless tutorials around the internet. \n","\n","In the method, several extra data, besides the image and label, are stored for each example (subject, age, sex, preprocessing and image ID). This was stored just in case these data were needed in forward steps, although, in the end, they were not. It does not really matter because the extra space needed was insignificant.  "]},{"cell_type":"code","metadata":{"id":"3vT13OdzLW5n","colab_type":"code","colab":{}},"source":["def create_tf_record(img_filenames, tf_rec_filename):\n","  ''' Create a TFRecord file, including the information\n","      of the specified images\n","      \n","      Parameters:\n","        img_filenames -- Array with the path to every\n","                         image that is going to be included\n","                         in the TFRecords file.\n","        tf_rec_filename -- Name of the TFRecords file.\n","  '''\n","  \n","  # open the file\n","  writer = tf.python_io.TFRecordWriter(tf_rec_filename)\n","  \n","  # iterate through all .nii files\n","  for meta_data in img_filenames:\n","\n","    # load the image and label\n","    img, label, subject = load_image_3D(meta_data)\n","    \n","    # also save the preprocessing information and the subject age and sex\n","    meta_data_split = meta_data.split('/')\n","    filename_split = meta_data_split[-1].split('_')\n","    \n","    # save the preprocessing technique used\n","    preprocessing = '_'.join(filename_split[5:-3])\n","    \n","    # get the image ID\n","    if filename_split[-1].endswith('.gz'): image_ID = int(filename_split[-1][1:-7])\n","    else: image_ID = int(filename_split[-1][1:-4])\n","      \n","    # get the age and sex of the subject\n","    age_and_sex = description.loc[description['Image Data ID'] == image_ID, ['Age', 'Sex']].iloc[0]\n","    \n","    # create a feature\n","    feature = {'label': _int64_feature(label),\n","               'subject': _bytes_feature(subject.encode('utf-8')),\n","               'preprocessing': _bytes_feature(preprocessing.encode('utf-8')),\n","               'subject_age': _int64_feature(age_and_sex[0]),\n","               'subject_sex': _bytes_feature(age_and_sex[1].encode('utf-8')),\n","               'image_id': _int64_feature(image_ID),\n","               'image': _float_feature(img.ravel())}\n","\n","    # create an example protocol buffer\n","    example = tf.train.Example(features=tf.train.Features(feature=feature))\n","\n","    # serialize to string and write on the file\n","    writer.write(example.SerializeToString())\n","    \n","  writer.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k7GScgSEduk0","colab_type":"text"},"source":["Define the complete path names for the `.tfrecords` files."]},{"cell_type":"code","metadata":{"id":"OrUmlCP9Mxm-","colab_type":"code","colab":{}},"source":["train_tfrec = os.path.join(DB_TF_3D_PATH, TFREC_3D_SS_TRAIN)\n","test_tfrec = os.path.join(DB_TF_3D_PATH, TFREC_3D_SS_TEST)\n","val_tfrec = os.path.join(DB_TF_3D_PATH, TFREC_3D_SS_VAL)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zWD8bAtRdzWh","colab_type":"text"},"source":["Finally, create the `.tfrecords` files. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"97AtZ1TkCdZw","colab":{}},"source":["create_tf_record(training_set, train_tfrec)\n","create_tf_record(test_set, test_tfrec)\n","create_tf_record(validation_set, val_tfrec)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uOete8hfHvMg"},"source":["### 2D TFRecords database for supervised learning\n","\n","Let´s build the 2D TFRecords database for supervised learning. Keep in mind that this code can be reused to create databases for both skull-stripped and non-skull-stripped data, just by modifying the referenced constants. The final work used skull-stripped data.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jbiAJT81eCJT","colab_type":"text"},"source":["In this case, images need to be transformed to 2D. The following method does exactly that, taking multiple horizontal slices and putting them in a 2D matrix. In the final version, 16 slices were used. Some considerations:\n","\n","* The top slice was selected manually, after some tests. Higher cuts did not show any useful information.\n","* The same for the bottom slice. Below slices only showed some of the brainstem. \n","* If 16 cuts were wanted, every two slices from 30 to 60 has to be selected."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9_KHgZFFzVAY","colab":{}},"source":["def slices_matrix_2D(img):\n","  ''' Transform a 3D MRI image into a 2D image, by obtaining 9 slices \n","      and placing them in a 4x4 two-dimensional grid.\n","      \n","      All 16 cuts are from a horizontal/axial view. They are selected\n","      from the 30th to the 60th level of the original 3D image.\n","      \n","      Parameters:\n","        img -- np.ndarray with the 3D image\n","        \n","      Returns:\n","        np.ndarray -- The resulting 2D image\n","  '''\n","  \n","  # create the final 2D image \n","  image_2D = np.empty(IMG_2D_SHAPE)\n","  \n","  # set the limits and the step\n","  TOP = 60\n","  BOTTOM = 30\n","  STEP = 2\n","  N_CUTS = 16\n","  \n","  # iterator for the cuts\n","  cut_it = TOP\n","  # iterator for the rows of the 2D final image\n","  row_it = 0\n","  # iterator for the columns of the 2D final image\n","  col_it = 0\n","  \n","  for cutting_time in range(N_CUTS):\n","    \n","    # cut\n","    cut = img[cut_it, :, :]\n","    cut_it -= STEP\n","    \n","    # reset the row iterator and move the\n","    # col iterator when needed\n","    if cutting_time in [4, 8, 12]:\n","      row_it = 0\n","      col_it += cut.shape[1]\n","    \n","    # copy the cut to the 2D image\n","    for i in range(cut.shape[0]):\n","      for j in range(cut.shape[1]):\n","        image_2D[i + row_it, j + col_it] = cut[i, j]\n","    row_it += cut.shape[0]\n","  \n","  # return the final 2D image, with 3 channels\n","  # this is necessary for working with most pre-trained nets\n","  return np.repeat(image_2D[None, ...], 3, axis=0).T\n","  #return image_2D"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mEtm6TmwfHSF","colab_type":"text"},"source":["The following method uses the previous 2D transformation to load the 3D images from disk and transforms them. Also returns the image label.\n","\n","The label mapper argument was intended to be used for modifying class labels, but it was never really used for anything special. It always used `LABELS` as the mapper."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N7b0bFBwtcGg","colab":{}},"source":["def load_image_2D(abs_path, labels):\n","  ''' Load an image (.nii) and its label, from its absolute path.\n","      Transform it into a 2D image, by obtaining 16 slices and placing them\n","      in a 4x4 two-dimensional grid.\n","      \n","      Parameters:\n","        abs_path -- Absolute path, filename included\n","        labels -- Label mapper\n","        \n","      Returns:\n","        img -- The .nii image, converted into a numpy array\n","        label -- The label of the image (from argument 'labels')\n","        \n","  '''\n","  \n","  # obtain the label from the path (it is the last directory name)\n","  label = labels[abs_path.split('/')[-2]]\n","  \n","  # load the image with SimpleITK\n","  sitk_image = sitk.ReadImage(abs_path)\n","  \n","  # transform into a numpy array\n","  img = sitk.GetArrayFromImage(sitk_image)\n","  \n","  # apply whitening\n","  img = preprocessing.whitening(img)\n","  \n","  # make the 2D image\n","  img = slices_matrix_2D(img)\n","  \n","  return img, label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s8govfQEfwjI","colab_type":"text"},"source":["Define the complete filename for each one of the `.tfrecords`."]},{"cell_type":"code","metadata":{"id":"VMnu_hDddOL8","colab_type":"code","colab":{}},"source":["train_tfrec2D = os.path.join(DB_TF_2D_PATH, TFREC_2D_SS_TRAIN)\n","test_tfrec2D = os.path.join(DB_TF_2D_PATH, TFREC_2D_SS_TEST)\n","val_tfrec2D = os.path.join(DB_TF_2D_PATH, TFREC_2D_SS_VAL)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6KaDhc0if11D","colab_type":"text"},"source":["Design the method for creating a `.tfrecords`, given the all the images filenames, the name of the file and the label mapper (always the `LABELS` constant). It uses the previous two methods for loading the images. "]},{"cell_type":"code","metadata":{"id":"4VfnvaC9dNRG","colab_type":"code","colab":{}},"source":["def create_tf_record_2D(img_filenames, tf_rec_filename, labels):\n","  ''' Create a TFRecord file, including the information\n","      of the specified images, after converting them into \n","      a 2D grid.\n","      \n","      Parameters:\n","        img_filenames -- Array with the path to every\n","                         image that is going to be included\n","                         in the TFRecords file.\n","        tf_rec_filename -- Name of the TFRecords file.\n","        labels -- Label mapper\n","  '''\n","  \n","  # open the file\n","  writer = tf.python_io.TFRecordWriter(tf_rec_filename)\n","  \n","  # iterate through all .nii files\n","  for meta_data in img_filenames:\n","\n","    # load the image and label\n","    img, label = load_image_2D(meta_data, labels)\n","\n","    # create a feature\n","    feature = {'label': _int64_feature(label),\n","               'image': _float_feature(img.ravel())}\n","\n","    # create an example protocol buffer\n","    example = tf.train.Example(features=tf.train.Features(feature=feature))\n","\n","    # serialize to string and write on the file\n","    writer.write(example.SerializeToString())\n","    \n","  writer.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"naTYQl11gNqN","colab_type":"text"},"source":["Finally, create the `.tfrecords`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uyMAdOL216Tc","colab":{}},"source":["create_tf_record_2D(training_set, train_tfrec2D, LABELS)\n","create_tf_record_2D(test_set, test_tfrec2D, LABELS)\n","create_tf_record_2D(validation_set, val_tfrec2D, LABELS)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ZFzWFuAkUQ0","colab_type":"text"},"source":["---\n","\n","### Train/Test unsupervised data split\n","\n","Save all file names in an array. Keep in mind that the data we have for supervised learning can also be used for unsupervised learning, so we need to access both databases this time."]},{"cell_type":"code","metadata":{"id":"aoxz-RXRkUYm","colab_type":"code","colab":{}},"source":["# array where we are going to save the filenames\n","filenames = np.array([])\n","\n","# iterate all three class folders in the supervised db\n","for subf in CLASS_SUBFOLDERS:\n","  path = DB_SS_PATH + subf\n","  for name in os.listdir(path):\n","    complete_name = os.path.join(path, name)\n","    if os.path.isfile(complete_name): \n","      filenames = np.concatenate((filenames, complete_name), axis=None)\n","    \n","for name in os.listdir(DB_UL_SS_PATH):\n","  complete_name = os.path.join(DB_UL_SS_PATH, name)\n","  if os.path.isfile(complete_name):\n","      filenames = np.concatenate((filenames, complete_name), axis=None)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xUzNS-Dek3Es","colab_type":"text"},"source":["Then shuffle and split:"]},{"cell_type":"code","metadata":{"id":"ZiUnliErkij_","colab_type":"code","colab":{}},"source":["for i in range(1000):\n","  np.random.shuffle(filenames)\n","  \n","test_margin = int(len(filenames) * TEST_SPLIT)\n","unsupervised_training_set, unsupervised_test_set = filenames[test_margin:], filenames[:test_margin]\n","\n","validation_margin = int(len(unsupervised_training_set) * VALIDATION_SPLIT)\n","unsupervised_training_set, unsupervised_validation_set = unsupervised_training_set[validation_margin:], unsupervised_training_set[:validation_margin]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"khsfAmeROV6t"},"source":["---\n","\n","## UNSUPERVISED DATA (DEPRECATED)\n","\n","### 3D TFRecords database for unsupervised learning\n","\n","Let´s build the 3D TFRecords database for unsupervised learning. Keep in mind that this code can be reused to create databases for both skull-stripped and non-skull-stripped data, just by modifying the referenced constants. \n","\n"]},{"cell_type":"code","metadata":{"id":"3eURTC2DfGLK","colab_type":"code","colab":{}},"source":["train_ul_tfrec = os.path.join(DB_TF_UL_PATH, TFREC_UL_SS_TRAIN)\n","test_ul_tfrec = os.path.join(DB_TF_UL_PATH, TFREC_UL_SS_TEST)\n","val_ul_tfrec = os.path.join(DB_TF_UL_PATH, TFREC_UL_SS_VAL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtvQamfrgB8Y","colab_type":"code","colab":{}},"source":["def unsupervised_load_image_3D(abs_path):\n","  ''' Load an image (.nii) from its absolute path.\n","      The associated label will be the image itself.\n","      This method is used for unsupervised learning.\n","      \n","      Parameters:\n","        abs_path -- Absolute path, filename included\n","        \n","      Returns:\n","        img -- The .nii image, converted into a numpy array        \n","  '''\n","   \n","  # load the image with SimpleITK\n","  sitk_image = sitk.ReadImage(abs_path)\n","  # transform into a numpy array\n","  img = sitk.GetArrayFromImage(sitk_image)\n","  \n","  split_path = abs_path.split('/')\n","  if split_path[-3] != 'UNSUPERVISED':\n","    split_name = split_path[-1].split('_')\n","    subject = '_'.join(split_name[1:4])\n","    preprocessing = '_'.join(split_name[5:-3])\n","  else:\n","    # for those images that come from the IXI dataset\n","    subject = 'IXI'\n","    preprocessing = 'IXI'\n","  \n","  return img, subject, preprocessing"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xRbbYyk6gPhe","colab_type":"code","colab":{}},"source":["def create_unsupervised_tf_record(img_filenames, tf_rec_filename):\n","  ''' Create a TFRecord file, including the information\n","      of the specified images\n","      \n","      Parameters:\n","        img_filenames -- Array with the path to every\n","                         image that is going to be included\n","                         in the TFRecords file.\n","        tf_rec_filename -- Name of the TFRecords file.\n","  '''\n","  \n","  exceptions = []\n","  \n","  # open the file\n","  writer = tf.python_io.TFRecordWriter(tf_rec_filename)\n","  \n","  # iterate through all .nii files\n","  for meta_data in img_filenames:\n","    \n","    try:\n","      # load the image and label\n","      img, subject, preprocessing = unsupervised_load_image_3D(meta_data)\n","    except:\n","      exceptions.append(meta_data)\n","\n","    # create a feature\n","    feature = {'subject': _bytes_feature(subject),\n","               'preprocessing': _bytes_feature(preprocessing),\n","               'image': _float_feature(img.ravel())}\n","\n","    # create an example protocol buffer\n","    example = tf.train.Example(features=tf.train.Features(feature=feature))\n","\n","    # serialize to string and write on the file\n","    writer.write(example.SerializeToString())\n","    \n","  writer.close()\n","  return exceptions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tX2uyyBgoAg","colab_type":"code","colab":{}},"source":["exceptions = create_unsupervised_tf_record(unsupervised_training_set, train_ul_tfrec)\n","exceptions.append(create_unsupervised_tf_record(unsupervised_test_set, test_ul_tfrec))\n","exceptions.append(create_unsupervised_tf_record(unsupervised_validation_set, val_ul_tfrec))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UUuUiNUECiGz","colab_type":"text"},"source":["---\n","\n","## PET IMAGES (DEPRECATED)"]},{"cell_type":"code","metadata":{"id":"fLTH-9LbCqoT","colab_type":"code","colab":{}},"source":["PET_DB_PATH = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/ADNI/PET/'\n","CLASS_SUBFOLDERS = ['MCI/', 'AD/', 'CN/']\n","\n","DB_TF_PET_PATH = '/content/gdrive/My Drive/Education/Master/MIA/TFM/Data/TFRecords/PET/TFRecords2D/'\n","# files\n","TFREC_2D_PET_TRAIN = 'train.pet.2D.tfrecords'\n","TFREC_2D_PET_TEST = 'test.pet.2D.tfrecords'\n","TFREC_2D_PET_VAL = 'validation.pet.2D.tfrecords'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7F00PqzJCqEE","colab_type":"code","colab":{}},"source":["LABELS = {'CN': 0, 'MCI': 1, 'AD': 2}\n","PET_IMG_SHAPE = (69, 95, 79)\n","PET_2D_SHAPE = (PET_IMG_SHAPE[1] * 4, PET_IMG_SHAPE[2] * 4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oYYTIU_FEULb","colab_type":"code","colab":{}},"source":["TEST_SPLIT = 0.15\n","VALIDATION_SPLIT = 0.15"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_QsKEXuqEXgH","colab_type":"text"},"source":["### Train/Test split"]},{"cell_type":"code","metadata":{"id":"nVkLck-6EZ4a","colab_type":"code","colab":{}},"source":["# array where we are going to save the filenames\n","filenames = np.array([])\n","\n","# iterate all three class folders in the db\n","for subf in CLASS_SUBFOLDERS:\n","  path = PET_DB_PATH + subf\n","  for name in os.listdir(path):\n","    complete_name = os.path.join(path, name)\n","    if os.path.isfile(complete_name):\n","      filenames = np.concatenate((filenames, complete_name), axis=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GL5OpjbMEaeG","colab_type":"code","colab":{}},"source":["for i in range(1000):\n","  np.random.shuffle(filenames)\n","  \n","test_margin = int(len(filenames) * TEST_SPLIT)\n","training_set, test_set = filenames[test_margin:], filenames[:test_margin]\n","\n","validation_margin = int(len(training_set) * VALIDATION_SPLIT)\n","training_set, validation_set = training_set[validation_margin:], training_set[:validation_margin]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bzNw3paZCmVk","colab_type":"text"},"source":["### 2D transformation"]},{"cell_type":"code","metadata":{"id":"2-IAcrl_En-w","colab_type":"code","colab":{}},"source":["def pet_to_2D(img):\n","  ''' Transform a 3D PET image into a 2D image, by obtaining 9 slices \n","      and placing them in a 4x4 two-dimensional grid.\n","      \n","      All 16 cuts are from a horizontal/axial view. They are selected\n","      from the ?th to the ?th level of the original 3D image.\n","      \n","      Parameters:\n","        img -- np.ndarray with the 3D image\n","        \n","      Returns:\n","        np.ndarray -- The resulting 2D image\n","  '''\n","  \n","  # create the final 2D image \n","  image_2D = np.empty(PET_2D_SHAPE)\n","  \n","  # set the limits and the step\n","  TOP = 50\n","  BOTTOM = 20\n","  STEP = 2\n","  N_CUTS = 16\n","  \n","  # iterator for the cuts\n","  cut_it = TOP\n","  # iterator for the rows of the 2D final image\n","  row_it = 0\n","  # iterator for the columns of the 2D final image\n","  col_it = 0\n","  \n","  for cutting_time in range(N_CUTS):\n","    \n","    # cut\n","    cut = img[cut_it, :, :]\n","    cut_it -= STEP\n","    \n","    # reset the row iterator and move the\n","    # col iterator when needed\n","    if cutting_time in [4, 8, 12]:\n","      row_it = 0\n","      col_it += cut.shape[1]\n","    \n","    # copy the cut to the 2D image\n","    for i in range(cut.shape[0]):\n","      for j in range(cut.shape[1]):\n","        image_2D[i + row_it, j + col_it] = cut[i, j]\n","    row_it += cut.shape[0]\n","  \n","  # return the final 2D image\n","  return np.repeat(image_2D[None, ...], 3, axis=0).T\n","  #return image_2D"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gqp5Iqe6Ey_8","colab_type":"code","colab":{}},"source":["def load_PET_2D(abs_path):\n","  ''' Load an image (.nii) and its label, from its absolute path.\n","      Transform it into a 2D image, by obtaining 16 slices and placing them\n","      in a 4x4 two-dimensional grid.\n","      \n","      Parameters:\n","        abs_path -- Absolute path, filename included\n","        \n","      Returns:\n","        img -- The .nii image, converted into a numpy array\n","        label -- The label of the image (CN/MCI/AD = 0/1/2)\n","        \n","  '''\n","  \n","  # obtain the label from the path (it is the last directory name)\n","  label = LABELS[abs_path.split('/')[-2]]\n","  \n","  # load the image with SimpleITK\n","  sitk_image = sitk.ReadImage(abs_path)\n","  \n","  # transform into a numpy array\n","  img = sitk.GetArrayFromImage(sitk_image)\n","  \n","  # apply whitening\n","  img = preprocessing.whitening(img)\n","  \n","  # make the 2D image\n","  img = pet_to_2D(img)\n","  \n","  return img, label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1JOtT28qgkAm","colab_type":"text"},"source":["### TFRecords creation"]},{"cell_type":"code","metadata":{"id":"O-vh7ZXRFVvz","colab_type":"code","colab":{}},"source":["train_tfrecPET = os.path.join(DB_TF_PET_PATH, TFREC_2D_PET_TRAIN)\n","test_tfrecPET = os.path.join(DB_TF_PET_PATH, TFREC_2D_PET_TEST)\n","val_tfrecPET = os.path.join(DB_TF_PET_PATH, TFREC_2D_PET_VAL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDBsG716Fghs","colab_type":"code","colab":{}},"source":["def tf_record_PET_2D(img_filenames, tf_rec_filename):\n","  ''' Create a TFRecord file, including the information\n","      of the specified images, after converting them into \n","      a 2D grid.\n","      \n","      Parameters:\n","        img_filenames -- Array with the path to every\n","                         image that is going to be included\n","                         in the TFRecords file.\n","        tf_rec_filename -- Name of the TFRecords file.\n","  '''\n","  \n","  # open the file\n","  writer = tf.python_io.TFRecordWriter(tf_rec_filename)\n","  \n","  # iterate through all .nii files\n","  for meta_data in img_filenames:\n","\n","    # load the image and label\n","    img, label = load_image_2D(meta_data)\n","\n","    # create a feature\n","    feature = {'label': _int64_feature(label),\n","               'image': _float_feature(img.ravel())}\n","\n","    # create an example protocol buffer\n","    example = tf.train.Example(features=tf.train.Features(feature=feature))\n","\n","    # serialize to string and write on the file\n","    writer.write(example.SerializeToString())\n","    \n","  writer.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRuisfK1FlU_","colab_type":"code","colab":{}},"source":["tf_record_PET_2D(training_set, train_tfrecPET)\n","tf_record_PET_2D(test_set, test_tfrecPET)\n","tf_record_PET_2D(validation_set, val_tfrecPET)"],"execution_count":0,"outputs":[]}]}